{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy, recall, specificity\n",
    "import pickle\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データ数 :  3956\n",
      "['../dataset/train/images/on/20201217_160_on_0000000067.jpg', '../dataset/train/images/on/20201217_007_on_0000000307.jpg', '../dataset/train/images/on/20201217_010_on_0000000026.jpg']\n",
      "検証データ数 :  990\n",
      "['../dataset/train/images/on/20201217_122_on_0000000039.jpg', '../dataset/train/images/on/20201217_029_on_0000000062.jpg', '../dataset/train/images/on/20201217_162_on_0000000361.jpg']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def make_filepath_list():\n",
    "    train_file_list = []\n",
    "    valid_file_list = []\n",
    "    num_sumples = len(os.listdir('../dataset/train/images/off'))\n",
    "    for top_dir in os.listdir('../dataset/train/images/'):\n",
    "        file_dir = os.path.join('../dataset/train/images/',top_dir)\n",
    "        if file_dir == '../dataset/train/images/._.DS_Store' or file_dir == '../dataset/train/images/.DS_Store':\n",
    "            continue\n",
    "        file_list = os.listdir(file_dir)\n",
    "        random.shuffle(file_list)\n",
    "        file_list = file_list[:num_sumples]\n",
    "\n",
    "        \n",
    "\n",
    "        #８割を学習データ、２割を検証データ\n",
    "        num_data = len(file_list)\n",
    "        num_split = int(num_data * 0.8)\n",
    "\n",
    "        train_file_list += [os.path.join('../dataset/train/images/',top_dir,file).replace('\\\\','/') for file in file_list[:num_split]]\n",
    "        valid_file_list += [os.path.join('../dataset/train/images/',top_dir,file).replace('\\\\','/') for file in file_list[num_split:]]\n",
    "\n",
    "    return train_file_list, valid_file_list\n",
    "\n",
    "train_file_list, valid_file_list = make_filepath_list()\n",
    "\n",
    "if '../dataset/train/images/on/._.DS_Store' in train_file_list:\n",
    "    train_file_list.remove('../dataset/train/images/on/._.DS_Store')\n",
    "if '../dataset/train/images/on/._.DS_Store' in valid_file_list:\n",
    "    valid_file_list.remove('../dataset/train/images/on/._.DS_Store')\n",
    "if '../dataset/train/images/off/._.DS_Store' in train_file_list:\n",
    "    train_file_list.remove('../dataset/train/images/off/._.DS_Store')\n",
    "if '../dataset/train/images/off/._.DS_Store' in valid_file_list:\n",
    "    valid_file_list.remove('../dataset/train/images/off/._.DS_Store')\n",
    "if '../dataset/train/images/on/.DS_Store' in train_file_list:\n",
    "    train_file_list.remove('../dataset/train/images/on/.DS_Store')\n",
    "if '../dataset/train/images/on/.DS_Store' in valid_file_list:\n",
    "    valid_file_list.remove('../dataset/train/images/on/.DS_Store')\n",
    "if '../dataset/train/images/off/.DS_Store' in train_file_list:\n",
    "    train_file_list.remove('../dataset/train/images/off/.DS_Store')\n",
    "if '../dataset/train/images/off/.DS_Store' in valid_file_list:\n",
    "    valid_file_list.remove('../dataset/train/images/off/.DS_Store')\n",
    "\n",
    "print('学習データ数 : ', len(train_file_list))\n",
    "print(train_file_list[:3])\n",
    "print('検証データ数 : ', len(valid_file_list))\n",
    "print(valid_file_list[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform(object):\n",
    "    def __init__(self,resize,mean,std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([ \n",
    "                #データオーグメンテーション\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                #画像をresizexresizeの大きさに統一する\n",
    "                transforms.Resize((resize,resize)),\n",
    "                #Tensor型に変換する\n",
    "                transforms.ToTensor(),\n",
    "                #色情報の標準化\n",
    "                transforms.Normalize(mean,std)\n",
    "            ]),\n",
    "            'valid': transforms.Compose([\n",
    "                transforms.Resize((resize,resize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean,std)\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize((resize,resize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean,std)\n",
    "            ])\n",
    "        }\n",
    "    def __call__(self, img, phase='train'):\n",
    "        return self.data_transform[phase](img)\n",
    "\n",
    "resize = 300\n",
    "mean = (0.5,0.5,0.5)\n",
    "std = (0.5,0.5,0.5)\n",
    "transform = ImageTransform(resize,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurgeryDataset(data.Dataset):\n",
    "    def __init__(self,file_list,classes,transform=None,phase='test'):\n",
    "        self.phase = phase\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        self.phase = phase\n",
    "    def __len__(self):\n",
    "        #画像の枚数を返す\n",
    "        return len(self.file_list)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        #前処理した画像データのTensor形式のデータとラベルを取得\n",
    "\n",
    "        #指定したindexの画像を読み込む\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        #画像の前処理を実施\n",
    "        img_transformed = self.transform(img,self.phase)\n",
    "\n",
    "        #画像ラベルをファイル名から抜き出す\n",
    "        if self.phase == 'train' or self.phase=='valid':\n",
    "            label = self.file_list[index].split('_')[-2]\n",
    "        else:\n",
    "            label = self.file_list[index].split('_')[-1][:-4]\n",
    "        \n",
    "\n",
    "        #ラベル名を数値に変換\n",
    "        label = self.classes.index(label)\n",
    "\n",
    "        return img_transformed, label\n",
    "\n",
    "surgery_classes = ['on','off']\n",
    "\n",
    "#Datasetの作成\n",
    "train_dataset = SurgeryDataset(\n",
    "    file_list=train_file_list,classes=surgery_classes,\n",
    "    transform=ImageTransform(resize,mean,std),\n",
    "    phase='train'\n",
    ")\n",
    "valid_dataset = SurgeryDataset(\n",
    "    file_list=valid_file_list,classes=surgery_classes,\n",
    "    transform=ImageTransform(resize,mean,std),\n",
    "    phase='valid'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "#バッチサイズの指定\n",
    "batch_size = 16\n",
    "\n",
    "#DataLoaderを作成\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    num_workers=0,shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_dataset,batch_size=16,num_workers=0,shuffle=True\n",
    ")\n",
    "\n",
    "# batch_iterator = iter(train_dataloader)\n",
    "# inputs, labels = next(batch_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'resnetv2_50'\n",
    "FEATS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnetv2_50_a1h-000cdf49.pth\" to /Users/taichii/.cache/torch/hub/checkpoints/resnetv2_50_a1h-000cdf49.pth\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | ResNetV2 | 23.5 M\n",
      "-----------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.018    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichii/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:376: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/taichii/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:14<00:00,  7.28s/it]valid Loss: 0.6947 valid Acc: 0.4688\n",
      "Epoch 0:   0%|          | 0/310 [00:00<00:00, 2409.13it/s]            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichii/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/taichii/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:405: LightningDeprecationWarning: One of the returned values {'batch_loss', 'y_hat', 'y'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  warning_cache.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 2/310 [00:45<1:18:30, 15.29s/it, loss=0.695, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichii/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    #ネットワークで使用する層を記述\n",
    "    def __init__(self,date=None):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(modelname, pretrained=True, num_classes=2)\n",
    "\n",
    "    #順伝搬処理を記述\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat,y)\n",
    "\n",
    "        return {'loss':loss, 'y_hat':y_hat, 'y':y,\n",
    "        'batch_loss':loss.item()*x.size(0)}\n",
    "\n",
    "    #各エポック終了時の処理を記述\n",
    "    def training_epoch_end(self, train_step_outputs):\n",
    "        y_hat = torch.cat([val['y_hat'] for val in \n",
    "        train_step_outputs], dim=0)\n",
    "        y = torch.cat([val['y'] for val in \n",
    "        train_step_outputs], dim=0)\n",
    "        epoch_loss = sum([val['batch_loss'] for val in \n",
    "        train_step_outputs]) / y_hat.size(0)\n",
    "\n",
    "        preds = torch.argmax(y_hat,dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log('train_loss', epoch_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('train_acc', acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        print('-------- Current Epoch {} --------'.format(self.current_epoch + 1))\n",
    "        print('train Loss: {:.4f} train Acc: {:.4f}'.format(epoch_loss, acc))\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        \n",
    "        return {'y_hat': y_hat, 'y': y, 'batch_loss': loss.item() * x.size(0)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        # x_hatを一つにまとめる\n",
    "        y_hat = torch.cat([val['y_hat'] for val in val_step_outputs], dim=0)\n",
    "        y = torch.cat([val['y'] for val in val_step_outputs], dim=0)\n",
    "        epoch_loss = sum([val['batch_loss'] for val in val_step_outputs]) / y_hat.size(0)\n",
    "\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        rec = recall(preds,y)\n",
    "        spec = specificity(preds,y)\n",
    "\n",
    "        self.log('val_loss', epoch_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_acc', acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        print('valid Loss: {:.4f} valid Acc: {:.4f} valid Recall: {:.4f} valid Specificity: {:.4f}'.format(epoch_loss, acc, rec, spec))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        \n",
    "        return {'y_hat': y_hat, 'y': y, 'batch_loss': loss.item() * x.size(0)}\n",
    "    \n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        # x_hatを一つにまとめる\n",
    "        y_hat = torch.cat([val['y_hat'] for val in test_step_outputs], dim=0)\n",
    "\n",
    "        y = torch.cat([val['y'] for val in test_step_outputs], dim=0)\n",
    "        # with open('../dataset/test/'+date+'/results/true.pickle', mode='wb') as f:\n",
    "        #     pickle.dump(y, f)\n",
    "        epoch_loss = sum([val['batch_loss'] for val in test_step_outputs]) / y_hat.size(0)\n",
    "\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        with open('../dataset/test/'+date+'/results/preds_bin.pickle', mode='wb') as f:\n",
    "            pickle.dump(preds, f)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        self.log('test_loss', epoch_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('test_acc', acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        print('test Loss: {:.4f} test Acc: {:.4f}'.format(epoch_loss, acc))\n",
    "\n",
    "    # 最適化手法を記述する\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.01)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "es = pl.callbacks.EarlyStopping(monitor='val_loss')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    callbacks=[es],\n",
    "    gpus = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader,\n",
    ")\n",
    "\n",
    "torch.save(net.state_dict(),'../models/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-date')\n",
    "\n",
    "args = parser.parse_args()\n",
    "date = args.date\n",
    "\n",
    "#テストデータのファイルパス\n",
    "test_file_list = []\n",
    "file_dir = '../dataset/test/'+date+'/images/'\n",
    "file_list = os.listdir(file_dir)\n",
    "test_file_list += [os.path.join('../dataset/test/'+date+'/images/',file).replace('\\\\','/') for file in file_list]\n",
    "test_file_list = sorted(test_file_list)\n",
    "if '../dataset/test/'+date+'/images/._.DS_Store' in test_file_list:\n",
    "    test_file_list.remove('../dataset/test/'+date+'/images/._.DS_Store')\n",
    "if '../dataset/test/'+date+'/images/.DS_Store' in test_file_list:\n",
    "    test_file_list.remove('../dataset/test/'+date+'/images/.DS_Store')\n",
    "\n",
    "with open('../dataset/test/'+date+'/results/path_list.pickle', mode='wb') as f:\n",
    "    pickle.dump(test_file_list, f)\n",
    "\n",
    "print('テストデータ数 : ', len(test_file_list))\n",
    "print(test_file_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SurgeryDataset(\n",
    "    file_list=test_file_list,classes=surgery_classes,\n",
    "    transform=ImageTransform(resize,mean,std),\n",
    "    phase='test'\n",
    ")\n",
    "index = 0\n",
    "\n",
    "#バッチサイズの指定\n",
    "batch_size = 32\n",
    "\n",
    "#DataLoaderを作成\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_dataset,batch_size=16,num_workers=16,shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('../weights/Learned_model.pt'))\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    gpus = 1,\n",
    ")\n",
    "\n",
    "trainer.test(model=net, dataloaders=test_dataloader )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abf113cd64bab04cd0f8dd20d07e32a7ac564fe12dab396e27d52bdbcc5d7dda"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
